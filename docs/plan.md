# nanochat-dotnet Project Plan

## Goal

Build a C#/.NET implementation of nanochat inference to deeply understand transformer architecture through building.

## Target

- **.NET Version:** .NET 10 (Latest LTS)
- **Approach:** Libraries first â†’ Replace with own implementations

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Tokenizer  â”‚â”€â”€â”€â–¶â”‚   GPT Model  â”‚â”€â”€â”€â–¶â”‚    Engine    â”‚
â”‚              â”‚    â”‚              â”‚    â”‚  (Inference) â”‚
â”‚ â€¢ Encode     â”‚    â”‚ â€¢ Embedding  â”‚    â”‚ â€¢ KV Cache   â”‚
â”‚ â€¢ Decode     â”‚    â”‚ â€¢ Attention  â”‚    â”‚ â€¢ Generate   â”‚
â”‚ â€¢ Special    â”‚    â”‚ â€¢ MLP        â”‚    â”‚ â€¢ Sample     â”‚
â”‚   tokens     â”‚    â”‚ â€¢ Blocks     â”‚    â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                   â”‚                   â”‚
        â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Chat CLI                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Phases

### Phase 1: Libraries (Get it Working)

Use existing libraries to get a working implementation quickly.

| Component | Library |
|-----------|---------|
| Tensors & Ops | TorchSharp-cpu |
| Tokenizer | Tiktoken (custom loader) |
| Weight Loading | TorchSharp (PyTorch .pt files) |

### Phase 2: Replace (Understand It)

Replace dependencies with own implementations in order of complexity:

1. Tokenizer â†’ Own BPE implementation
2. RMSNorm â†’ Simple, no learnable params
3. RoPE â†’ Rotary embeddings from scratch
4. Attention â†’ Scaled dot-product, causal mask
5. MLP â†’ Linear layers, ReLUÂ²
6. Tensor Ops â†’ Own matmul, softmax, etc.

---

## Features & User Stories

### Feature 1: Project Foundation

**Goal:** Solution structure, dependencies, builds successfully

| Story | Description | Acceptance Criteria | Status |
|-------|-------------|---------------------|--------|
| 1.1 | Create solution and project structure | `dotnet build` succeeds | âœ… |
| 1.2 | Add TorchSharp-cpu dependency | Can create tensor, run matmul | âœ… |
| 1.3 | Add test project | `dotnet test` runs | âœ… |

---

### Feature 2: Tokenizer

**Goal:** Encode/decode text compatible with nanochat

| Story | Description | Acceptance Criteria | Status |
|-------|-------------|---------------------|--------|
| 2.1 | Create tokenizer interface | `ITokenizer` with Encode/Decode | âœ… |
| 2.2 | Implement tiktoken-based tokenizer | Load mergeable_ranks, encode text | âœ… |
| 2.3 | Add special token support | Encode `<\|bos\|>`, `<\|user_start\|>`, etc. | âœ… |
| 2.4 | Load nanochat tokenizer from disk | Read `tokenizer.pkl` format | âœ… |
| 2.5 | Test against Python implementation | Same input â†’ same token IDs | âœ… |

---

### Feature 3: Model Components

**Goal:** Implement all GPT building blocks

| Story | Description | Acceptance Criteria | Status |
|-------|-------------|---------------------|--------|
| 3.1 | Implement RMSNorm | `norm(x)` matches Python output | âœ… |
| 3.2 | Implement Rotary Embeddings | Precompute cos/sin, apply to Q/K | âœ… |
| 3.3 | Implement Multi-Head Attention | Causal self-attention works | âœ… |
| 3.4 | Implement GQA (Group-Query Attention) | n_kv_head < n_head works | âœ… |
| 3.5 | Implement MLP block | ReLUÂ² activation | âœ… |
| 3.6 | Implement Transformer Block | Attention + MLP + residuals | âœ… |
| 3.7 | Implement Value Embeddings | ResFormer-style alternating VE | âœ… |

---

### Feature 4: GPT Model

**Goal:** Full model that can compute logits

| Story | Description | Acceptance Criteria | Status |
|-------|-------------|---------------------|--------|
| 4.1 | Implement GPTConfig | Dataclass with all hyperparams | âœ… |
| 4.2 | Implement GPT model shell | Embeddings, blocks, lm_head | âœ… |
| 4.3 | Implement forward pass | Input tokens â†’ logits | âœ… |
| 4.4 | Add softcap to logits | `15 * tanh(logits / 15)` | âœ… |
| 4.5 | Add sliding window support | Per-layer window sizes | âœ… |

---

### Feature 5: Weight Loading

**Goal:** Load pretrained nanochat checkpoint

| Story | Description | Acceptance Criteria | Status |
|-------|-------------|---------------------|--------|
| 5.1 | Parse PyTorch checkpoint format | Read `.pt` file structure | âœ… |
| 5.2 | Map weight names to model | Handle naming differences | âœ… |
| 5.3 | Load weights into model | All parameters populated | âœ… |
| 5.4 | Verify loaded weights | Forward pass matches Python | âœ… |

---

### Feature 6: Inference Engine

**Goal:** Generate text autoregressively

| Story | Description | Acceptance Criteria | Status |
|-------|-------------|---------------------|--------|
| 6.1 | Implement naive generation | No cache, works correctly | âœ… |
| 6.2 | Implement temperature sampling | Adjustable randomness | âœ… |
| 6.3 | Implement top-k sampling | Filter low-probability tokens | âœ… |
| 6.4 | Implement KV-Cache | KVCache class with tests | âœ… |
| 6.5 | Integrate KV-Cache into generation | Cached inference works | âœ… |
| 6.6 | Optimize generation loop | Streaming token output | â¬œ |

---

### Feature 7: Chat Interface

**Goal:** Interactive CLI chat

| Story | Description | Acceptance Criteria | Status |
|-------|-------------|---------------------|--------|
| 7.1 | Implement conversation rendering | Format messages with special tokens | â¬œ |
| 7.2 | Implement CLI input loop | Read user input | â¬œ |
| 7.3 | Implement streaming output | Tokens appear as generated | â¬œ |
| 7.4 | Handle conversation history | Multi-turn works | â¬œ |

---

## nanochat-Specific Implementation Details

Key details from the Python implementation that must be matched:

| Aspect | Implementation |
|--------|----------------|
| Norm | `F.rms_norm()` - no learnable parameters |
| Activation | `ReLUÂ²` (relu then square) |
| Position Encoding | Rotary (RoPE), base=10000 |
| QK Norm | Applied after RoPE |
| Attention | GQA support, sliding windows |
| Logit Softcap | `15 * tanh(x/15)` |
| Residual | Per-layer `resid_lambdas` and `x0_lambdas` |
| Value Embeddings | Alternating layers, gated |
| Vocab Size | 32768 (padded to multiple of 64) |
| Sequence Length | 2048 |

## GPTConfig Defaults

```
sequence_len: 2048
vocab_size: 32768
n_layer: 12
n_head: 6
n_kv_head: 6
n_embd: 768
window_pattern: "SSSL"
```

---

## References

- [Attention Is All You Need (Original Paper)](https://arxiv.org/abs/1706.03762)
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [RoPE: Rotary Position Embedding](https://arxiv.org/abs/2104.09864)
- [RMSNorm Paper](https://arxiv.org/abs/1910.07467)
- [TorchSharp NuGet](https://www.nuget.org/packages/TorchSharp-cpu)
- [Tiktoken for .NET](https://github.com/microsoft/Tokenizer)

---

## Status Legend

- â¬œ Not started
- ğŸŸ¡ In progress
- âœ… Complete
- âŒ Blocked
